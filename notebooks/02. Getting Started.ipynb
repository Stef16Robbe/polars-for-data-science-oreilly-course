{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1653908d",
   "metadata": {},
   "source": [
    "# 02. Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a37bab",
   "metadata": {},
   "source": [
    "The goal of this module is to create `polars` dataframes in memory and by loading data; become familiar with `polars`'s lazy-mode versus in-memory mode; understand how to leverage `polars`'s query optimization; and become familiar with how to generate some basic summary statistics about a dataframe.\n",
    "\n",
    "If you had any issues installing the environment, please write me directly: benfeifke@gmail.com."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb12106c-7b18-4b87-a22e-02545d9346c3",
   "metadata": {},
   "source": [
    "Note: to set up your environment, head over to the Github page for this course: https://github.com/bfeif/polars-for-data-science-oreilly-course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1109c3fe",
   "metadata": {},
   "source": [
    "## 2.0. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f93cb",
   "metadata": {},
   "source": [
    "Import `polars`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3db2bd08",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff3475d",
   "metadata": {},
   "source": [
    "## 2.1. Creating a `pl.DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8396d2",
   "metadata": {},
   "source": [
    "The main entrypoint to any work we'll do in `polars` is the dataframe. If you're familiar with creating a dataframe in `pandas`, creating a dataframe in `polars` is very similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de06f5a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "scratch_df = pl.DataFrame({\n",
    "    \"customer_id\": [1, 2, 3,],\n",
    "    \"first_name\": [\"dan\", \"stan\", \"jan\",],\n",
    "    \"last_name\": [\"hanson\", \"flanson\", \"ransom\",],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8dae31",
   "metadata": {},
   "source": [
    "In a Jupyter Notebook, we can easily display the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69cf1d8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>customer_id</th><th>first_name</th><th>last_name</th></tr><tr><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;dan&quot;</td><td>&quot;hanson&quot;</td></tr><tr><td>2</td><td>&quot;stan&quot;</td><td>&quot;flanson&quot;</td></tr><tr><td>3</td><td>&quot;jan&quot;</td><td>&quot;ransom&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 3)\n",
       "┌─────────────┬────────────┬───────────┐\n",
       "│ customer_id ┆ first_name ┆ last_name │\n",
       "│ ---         ┆ ---        ┆ ---       │\n",
       "│ i64         ┆ str        ┆ str       │\n",
       "╞═════════════╪════════════╪═══════════╡\n",
       "│ 1           ┆ dan        ┆ hanson    │\n",
       "│ 2           ┆ stan       ┆ flanson   │\n",
       "│ 3           ┆ jan        ┆ ransom    │\n",
       "└─────────────┴────────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(scratch_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2353a618",
   "metadata": {},
   "source": [
    "Or `polars` offers a great output style if we're printing it as if we're in the console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59235361",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 3)\n",
      "┌─────────────┬────────────┬───────────┐\n",
      "│ customer_id ┆ first_name ┆ last_name │\n",
      "│ ---         ┆ ---        ┆ ---       │\n",
      "│ i64         ┆ str        ┆ str       │\n",
      "╞═════════════╪════════════╪═══════════╡\n",
      "│ 1           ┆ dan        ┆ hanson    │\n",
      "│ 2           ┆ stan       ┆ flanson   │\n",
      "│ 3           ┆ jan        ┆ ransom    │\n",
      "└─────────────┴────────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "print(scratch_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581aa162",
   "metadata": {},
   "source": [
    "We already see some cool things, like the way that `polars` explicitly tells us the shape and dtypes of the dataframe when we print it. But you didn't come here for fake data, did you? Let's load some real data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368150ba",
   "metadata": {},
   "source": [
    "## 2.2. Reading Data From `csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c31a1",
   "metadata": {},
   "source": [
    "The data used throughout this course will be data from taxi rides in New York City, offered publicly by the city: https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page (see a detailed description of the schema of this dataset [here](https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf)).\n",
    "\n",
    "There are many ways to load data in `polars`: from `csv` files, `parquet` files, `xlsx` files, or even directly from databases. We'll start with a `csv`, with the function `polars.read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced0e300-8e73-412e-a671-a97fca7b1745",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ben/code/polars-oreilly-course/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c29ce91",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "could not parse `�5�;j���{�s�:u9(Fc��s�p>\u0002��S���e����L��\"�D��\u0010�\u0014�)\" \u0019H\u0014^�@�t�O�*�>\u0007�` as dtype `str` at column 'PAR1\u0015\u0004\u0015\u0010\u0015\"L\u0015\u0004\u0015\u0000\u0012\u0000\u0000(�/� \bA\u0000\u0000\u0001\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0015\u0000\u0015�\u0013\u0015��\u000f' (column number 1)\n\nThe current offset in the file is 594 bytes.\n\nYou might want to try:\n- increasing `infer_schema_length` (e.g. `infer_schema_length=10000`),\n- specifying correct dtype with the `dtypes` argument\n- setting `ignore_errors` to `True`,\n- adding `�5�;j���{�s�:u9(Fc��s�p>\u0002��S���e����L��\"�D��\u0010�\u0014�)\" \u0019H\u0014^�@�t�O�*�>\u0007�` to the `null_values` list.\n\nOriginal error: ```invalid utf-8 sequence```",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mComputeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/yellow_tripdata_2024-03.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/polars-oreilly-course/.venv/lib/python3.9/site-packages/polars/_utils/deprecation.py:135\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    132\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m    133\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, version\n\u001b[1;32m    134\u001b[0m     )\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/polars-oreilly-course/.venv/lib/python3.9/site-packages/polars/_utils/deprecation.py:135\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    132\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m    133\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, version\n\u001b[1;32m    134\u001b[0m     )\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping similar frames: deprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper at line 135 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/code/polars-oreilly-course/.venv/lib/python3.9/site-packages/polars/_utils/deprecation.py:135\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    132\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m    133\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, version\n\u001b[1;32m    134\u001b[0m     )\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/polars-oreilly-course/.venv/lib/python3.9/site-packages/polars/io/csv/functions.py:422\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(source, has_header, columns, new_columns, separator, comment_prefix, quote_char, skip_rows, schema, schema_overrides, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, use_pyarrow, storage_options, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines, decimal_comma, glob)\u001b[0m\n\u001b[1;32m    410\u001b[0m         schema_overrides \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    411\u001b[0m             new_to_current\u001b[38;5;241m.\u001b[39mget(column_name, column_name): column_dtype\n\u001b[1;32m    412\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m column_name, column_dtype \u001b[38;5;129;01min\u001b[39;00m schema_overrides\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    413\u001b[0m         }\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m prepare_file_arg(\n\u001b[1;32m    416\u001b[0m     source,\n\u001b[1;32m    417\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    420\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    421\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[0;32m--> 422\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43m_read_csv_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprojection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseparator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquote_char\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnull_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnull_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_utf8_is_empty_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_utf8_is_empty_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtry_parse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtry_parse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf8-lossy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrechunk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrechunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_rows_after_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_rows_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow_index_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_index_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow_index_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_index_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43meol_char\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meol_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraise_if_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_if_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal_comma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal_comma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mglob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_columns:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _update_columns(df, new_columns)\n",
      "File \u001b[0;32m~/code/polars-oreilly-course/.venv/lib/python3.9/site-packages/polars/io/csv/functions.py:568\u001b[0m, in \u001b[0;36m_read_csv_impl\u001b[0;34m(source, has_header, columns, separator, comment_prefix, quote_char, skip_rows, schema, schema_overrides, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines, decimal_comma, glob)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    566\u001b[0m projection, columns \u001b[38;5;241m=\u001b[39m parse_columns_arg(columns)\n\u001b[0;32m--> 568\u001b[0m pydf \u001b[38;5;241m=\u001b[39m \u001b[43mPyDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprojection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrechunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquote_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessed_null_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing_utf8_is_empty_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_parse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_rows_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_row_index_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_index_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_index_offset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43meol_char\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meol_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraise_if_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_if_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecimal_comma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal_comma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(pydf)\n",
      "\u001b[0;31mComputeError\u001b[0m: could not parse `�5�;j���{�s�:u9(Fc��s�p>\u0002��S���e����L��\"�D��\u0010�\u0014�)\" \u0019H\u0014^�@�t�O�*�>\u0007�` as dtype `str` at column 'PAR1\u0015\u0004\u0015\u0010\u0015\"L\u0015\u0004\u0015\u0000\u0012\u0000\u0000(�/� \bA\u0000\u0000\u0001\u0000\u0000\u0000\u0002\u0000\u0000\u0000\u0015\u0000\u0015�\u0013\u0015��\u000f' (column number 1)\n\nThe current offset in the file is 594 bytes.\n\nYou might want to try:\n- increasing `infer_schema_length` (e.g. `infer_schema_length=10000`),\n- specifying correct dtype with the `dtypes` argument\n- setting `ignore_errors` to `True`,\n- adding `�5�;j���{�s�:u9(Fc��s�p>\u0002��S���e����L��\"�D��\u0010�\u0014�)\" \u0019H\u0014^�@�t�O�*�>\u0007�` to the `null_values` list.\n\nOriginal error: ```invalid utf-8 sequence```"
     ]
    }
   ],
   "source": [
    "df = pl.read_csv(\"../data/yellow_tripdata_2024-03.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80743b",
   "metadata": {},
   "source": [
    "We can take a quick look at the data with a call to `.head()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9455839",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54622dd0",
   "metadata": {},
   "source": [
    "One thing that's nice about the `polars.DataFrame.head()` operation is the way that it shows the datatype of every column, making the schema explicitly clear. In this case, we have 19 columns:\n",
    "1. `'VendorID'`: `Int64`\n",
    "2. `'tpep_pickup_datetime'`: `String`\n",
    "3. `'tpep_dropoff_datetime'`: `String`\n",
    "4. `'passenger_count'`: `Int64`\n",
    "5. `'trip_distance'`: `Float64`\n",
    "6. `'RatecodeID'`: `Int64`\n",
    "7. `'store_and_fwd_flag'`: `String`\n",
    "8. `'PULocationID'`: `Int64`\n",
    "9. `'DOLocationID'`: `Int64`\n",
    "10. `'payment_type'`: `Int64`\n",
    "11. `'fare_amount'`: `Float64`\n",
    "12. `'extra'`: `Float64`\n",
    "13. `'mta_tax'`: `Float64`\n",
    "14. `'tip_amount'`: `Float64`\n",
    "15. `'tolls_amount'`: `Float64`\n",
    "16. `'improvement_surcharge'`: `Float64`\n",
    "17. `'total_amount'`: `Float64`\n",
    "18. `'congestion_surcharge'`: `Float64`\n",
    "19. `'Airport_fee'`: `Float64`\n",
    "\n",
    "You might have noticed something strange--why are `tpep_pickup_datetime` and `tpep_dropoff_datetime` recognized as a `string` datatype? After all, they look a lot like datetimes...\n",
    "\n",
    "Well, `polars.read_csv()` doesn't do much to detect datatypes beyond strings and numbers upon reading in data... unless of course you ask it to! This can be done with a simple inclusion of the `schema_overrides` argument to the `polars.read_csv()` call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e8356f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = pl.read_csv(\n",
    "    \"../data/yellow_tripdata_2024-03.csv\",\n",
    "    schema_overrides={\"tpep_pickup_datetime\": pl.Datetime, \"tpep_dropoff_datetime\": pl.Datetime}#, \"passenger_count\": pl.Datetime}\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024880c9",
   "metadata": {},
   "source": [
    "Now `\"tpep_pickup_datetime\"` and `\"tpep_dropoff_datetime\"` are parsed as datetimes, just as we wanted.\n",
    "\n",
    "This is one of the greatest strenghts of `polars`: easily managing data types and making them organized and transparent for users. This might not seem like a big deal right now, but when it comes time to do complex operations on columns, you'll very much appreciate this! But more on that in a few modules. For now, what else can we learn about this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1c1f27",
   "metadata": {},
   "source": [
    "We can see the shape of the whole dataframe with `pl.DataFrame.shape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba12a9e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5c0e94",
   "metadata": {},
   "source": [
    "That's a lot of data! We can also see a brief set of summary statistics about the dataframe with `pl.DataFrame.describe()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5bad08",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f2beb1",
   "metadata": {},
   "source": [
    "Here we can see how many null and non-null values are in each column, the average and standard deviation of each column, and the key quantiles of each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fddd02",
   "metadata": {},
   "source": [
    "Now, it's time to get lazy... let's try loading data with `polars` in lazy mode!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c44cc5",
   "metadata": {},
   "source": [
    "## 2.3. Scanning Data From `csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f49cd3",
   "metadata": {},
   "source": [
    "As we mentioned in the previous module, `polars` supports two ways of loading and processing data: the in-memory mode with `DataFrame`, and the lazy mode with `LazyFrame`. With `DataFrame`, all operations are executed as they are written; with `LazyFrame`, however, operations are optimized before they are executed.\n",
    "\n",
    "The most common way to enter lazy mode is by starting with `polars.scan_csv()` instead of `polars.read_csv()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2840091",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lf = pl.scan_csv(\n",
    "    \"../data/yellow_tripdata_2024-03.csv\",\n",
    "    schema_overrides={\"tpep_pickup_datetime\": pl.Datetime, \"tpep_dropoff_datetime\": pl.Datetime}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37e8bae",
   "metadata": {},
   "source": [
    "That's right--we can use the `schema_overrides` argument with `polars.scan_csv()` as well! `polars.scan_csv()` supports (almost) all the same input arguments as `polars.read_csv()`, making it easy to work with.\n",
    "\n",
    "As in the last section, let's do `head()` to take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf23d81",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b88a74",
   "metadata": {},
   "source": [
    "Hey, that's not a dataframe!\n",
    "\n",
    "When working with a `LazyFrame`, it's better to think of it as a \"query\" rather than as a \"dataframe\". To this end, displaying a `LazyFrame` object doesn't show the data result; rather, **it shows you what the computer is going to do to get you the data result**.\n",
    "\n",
    "In this case (reading the graph in the image from bottom to top), polars will:\n",
    "- `pl.scan_csv(...)`: scan the csv, selecting all columns (\"π \\*/19\") and filtering None (\"σ None\").\n",
    "- `.head()`: Take the first five rows (\"SLICE offset: 0; len: 5\").\n",
    "\n",
    "_Note: If this didn't work for you, you need to install `graphviz`. You can read more about how to do that on the [`graphviz` website](https://graphviz.org/download/)._\n",
    "\n",
    "_Another note: If the syntax here with π and σ looks weird to you, that's relational algebra, the formal algebra and notation underlying relational data (i.e. columnar data). For a deeper look into that, check out [the Wikipedia page about it](https://en.wikipedia.org/wiki/Relational_algebra)._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00feec4",
   "metadata": {},
   "source": [
    "You might also notice that, the graph instructs us to *\"run **LazyFrame.show_graph()** to see the optimized version\"*. Let's do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef18eba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lf.head().show_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564b9ca",
   "metadata": {},
   "source": [
    "Looks the same as the naive query plan--nothing to optimize here! Either way, we can see the result of the data with a call to `.collect()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b22d2d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lf.head().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f0355",
   "metadata": {},
   "source": [
    "Now you can load `csv`'s the in-memory way, and the lazy way--great! Now, let's actually do something beyond just loading... something that will trigger the query optimization engine..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e78db",
   "metadata": {},
   "source": [
    "## 2.4. Selecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9c2c20",
   "metadata": {},
   "source": [
    "Now that we have the data loaded--both as a `polars.DataFrame` and as a `polars.LazyFrame`--it's time to start querying it! Let's start with the most straightforward: selecting.\n",
    "\n",
    "If you're coming from `pandas`, the notation for selecting columns is with brackets, like `pandas.Dataframe[]`; if you're coming from `SQL`, the notation is `SELECT`. `Polars` is more like `SQL`, the notation is `polars.DataFrame.select()`.\n",
    "\n",
    "Suppose we only want to know the pickup and dropoff time of each taxi ride..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25268035",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .select([\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"])\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b96b5e",
   "metadata": {},
   "source": [
    "Easy! Let's see what that looks like with the `LazyFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88028b1a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lf\n",
    "    .select([\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"])\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9274c712",
   "metadata": {},
   "source": [
    "Again, you can see the naively sequential order of the query in the naive query plan:\n",
    "- `pl.scan_csv(...)`: scan the csv, selecting all columns (\"π \\*/19\") and filtering None (\"σ None\").\n",
    "- `.select(...)`: select two columns (\"π 2/2\").\n",
    "- `.head()`: Take the first five rows (\"SLICE offset: 0; len: 5\").\n",
    "\n",
    "But let's see what `Polars` will *actually* do to execute the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0dc8ed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lf\n",
    "    .select([\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"])\n",
    "    .head()\n",
    "    .show_graph()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5990721c",
   "metadata": {},
   "source": [
    "It's different! Rather than the naive query plan, in which all 19 columns are selected during the data loading, only to be selected down to 2 columns immediately thereafter, the optimized query plan shows that the two columns `\"tpep_pickup_datetime\"` and `\"tpep_dropoff_datetime\"` are being selected **while** the CSV is being read! This means that **the other 17 columns are never loaded into memory**, giving your code a massive boost in storage performance, and run performance during reading.\n",
    "\n",
    "Let's run the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9929a89f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    lf\n",
    "    .select([\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"])\n",
    "    .head()\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa1d87d",
   "metadata": {},
   "source": [
    "And the result is identical to doing it with `DataFrame`! But before moving on, let's see--how much of a boost to run-performance did we get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1d3d7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%timeit -n 3\n",
    "(\n",
    "    pl.read_csv(\n",
    "        \"../data/yellow_tripdata_2024-03.csv\",\n",
    "        schema_overrides={\"tpep_pickup_datetime\": pl.Datetime, \"tpep_dropoff_datetime\": pl.Datetime}\n",
    "    )\n",
    "    .select([\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6226416",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%timeit -n 3\n",
    "(\n",
    "    pl.scan_csv(\n",
    "        \"../data/yellow_tripdata_2024-03.csv\",\n",
    "        schema_overrides={\"tpep_pickup_datetime\": pl.Datetime, \"tpep_dropoff_datetime\": pl.Datetime}\n",
    "    )\n",
    "    .select([\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"])\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff3d9f1",
   "metadata": {},
   "source": [
    "Almost a 3x speed increase!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b2f006",
   "metadata": {},
   "source": [
    "You'll also notice, again, that the syntax for selecting columns with the `polars.LazyFrame` is identical to the syntax for selecting columns with `polars.DataFrame`. In almost all cases, this is true in `Polars`--that the syntax for the two is the same, only that `polars.LazyFrame` requires a `.collect()` call to actually return data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b7c2b",
   "metadata": {},
   "source": [
    "It's also worth mentioning here that, while we can easily convert a `pl.LazyFrame` to a `pl.DataFrame` with `.collect()`, the same can be done in the opposite direction with `pl.DataFrame.lazy()`. Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0629fc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_as_lazy = (\n",
    "    pl.read_csv(\n",
    "        \"../data/yellow_tripdata_2024-03.csv\",\n",
    "        schema_overrides={\"tpep_pickup_datetime\": pl.Datetime, \"tpep_dropoff_datetime\": pl.Datetime}\n",
    "    )\n",
    "    .lazy()\n",
    ")\n",
    "type(df_as_lazy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c228e3",
   "metadata": {},
   "source": [
    "Before moving onto the next module, let's try loading in one more file type: `parquet`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e17a1a3",
   "metadata": {},
   "source": [
    "## 2.5. Reading and Scanning From `parquet`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49834d80",
   "metadata": {},
   "source": [
    "In the course introduction, we saw that `polars` uses the Apache Arrow columnar memory format, a memory format that's optimized for modern column-oriented analytics use-cases, where columns are more important than rows. Apache Arrow optimizes for modern column-oriented analytics use-cases by placing values in a column next to each other in memory, rather than placing values in a row next to each other in memory.\n",
    "\n",
    "Well, there's also a file type that uses the Apache Arrow columnar memory format--`parquet`. Due to this connection, `polars` and `parquet` work very well together, and are a great toolkit for data science.\n",
    "\n",
    "Let's try and read and scan data from parquet in the same way we did for `csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1128812d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = pl.read_parquet(\"../data/yellow_tripdata_2024-03.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6d403",
   "metadata": {},
   "source": [
    "Something's changed--the `\"tpep_pickup_datetime\"` and `\"tpep_dropoff_datetime\"` get automatically read in as `datetime` data type! But why is that?\n",
    "\n",
    "Similar to how `polars` places a high importance on data types, so does `parquet`; with this, it's possible to store columns' data types alongside the data in a `parquet` file. This is something that `csv` just can't do!\n",
    "\n",
    "And, of course, there's also `scan_parquet()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74446421",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pl.scan_parquet(\"../data/yellow_tripdata_2024-03.parquet\").head().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421516e1",
   "metadata": {},
   "source": [
    "## 2.6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a52b2f",
   "metadata": {},
   "source": [
    "In this module, we've learned:\n",
    "- How to create a dataframe from scratch;\n",
    "- How to load data to a dataframe, both from `csv` and from `parquet`, and display some basic information about it;\n",
    "- How to work with in-memory mode vs lazy mode, and the performance difference that can be expected beteween the two;\n",
    "- How to begin writing queries, with the `select` function, and how this is executed differently in in-memory vs lazy mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a72630a",
   "metadata": {},
   "source": [
    "In the next module, \"Data Manipulation I: Basics\", we'll go deeper into manipulating dataframes. As a note, since this course has a more practical focus, from here on out only `DataFrame`s will be used, for syntactic brevity. As noted in this module, however, note that `DataFrame` and `LazyFrame` can almost always be used interchangeably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f1ebd-ad2f-4b6b-b22f-eb881c20d241",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73c0428-3ded-4881-b42a-8f331077f1e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7df3f1-5ac1-40a3-8999-8f7ad2f23a94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847918fe-baf0-4085-adb0-aa1c9f50505d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f197c-18b4-4bd2-828c-7b75353f2d44",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f1359-db61-4504-9ca9-e4e402e4c895",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

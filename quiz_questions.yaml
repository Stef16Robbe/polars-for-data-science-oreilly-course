- module_name: "Course Overview"
  quiz_questions: []
- module_name: "Introduction to Polars"  # 5 questions
  quiz_questions:
    - question: "What language is Polars implemented in?"
      answers:
        - text: "Rust"
          rationale: "Correct! Polars is implemented in Rust, and has bindings in other languages, all of which use the underlying Rust implementation."
          is_correct: true
        - text: "C"
          rationale: "C is indeed a fast low-level language, but it's not the one that Polars is implemented in."
          is_correct: false
        - text: "Python"
          rationale: "Though Polars has Python bindings, it is implemented in a different language!"
          is_correct: false
        - text: "R"
          rationale: "R is a great language for data science, but Polars is not implemented in R."
          is_correct: false
    - question: "Which is the most common use-case for Polars?"
      answers:
        - text: "Single node computing."
          rationale: "Correct!"
          is_correct: true
        - text: "Distributed computing."
          rationale: "Not really; tools like Spark or Modin are better suited to this use-case."
          is_correct: false
    - question: "What do you have to do to configure Polars such that its query optimization engine uses all cores available on the host machine?"
      answers:
        - text: "Specify a backend engine for distributing queries."
          rationale: "This is what you have to do with Modin and Ray for Pandas, not Polars."
          is_correct: false
        - text: "Enter some information regarding your OS's specifics into a configuration file which Polars will then use to distribute resources."
          rationale: "Nope!"
          is_correct: false
        - text: "Nothing, it works like that right out of the box."
          rationale: "Correct!"
          is_correct: true
        - text: "Specify the number of cores on the local machine when importing Polars."
          rationale: "Nope!"
          is_correct: false
    - question: "What does Polars use as its underlying memory model?"
      answers:
        - text: "Rust"
          rationale: "Polars is implemented in Rust, but that is not the underlying memory model."
          is_correct: false
        - text: "Python"
          rationale: "Polars has bindings in Python, but that is not its underlying memory model."
          is_correct: false
        - text: "Apache Arrow"
          rationale: "Correct!"
          is_correct: true
        - text: "Online Analytical Processing"
          rationale: "Polars uses a memory model which optimized for Online Analytical Processing use-cases, but that is not the memory model itself."
          is_correct: true
    - question: "How is the Apache Arrow memory model optimized for column-oriented OLAP use-cases?"
      answers:
        - text: "Data from the same column is placed close together in memory."
          rationale: "Exactly! Modern analytics use-cases usually involve column-oriented actions, so having data from the same column close together helps Apache Arrow to optimize for those use-cases."
          is_correct: true
        - text: "Data from the same row is placed close together in memory."
          rationale: "Incorrect! You might be thinking about OLTP, but Apache Arrow is optimized for OLAP."
          is_correct: false
        - text: "Data's storage location is close to the data's processing location."
          rationale: "This is an interesting design consideration that differs across distributed computing tools like Hadoop and Spark, but it's not relevant here."
          is_correct: false
        - text: "Data gets sorted before processing."
          rationale: "Incorrect! Try again."
          is_correct: false
- module_name: "Getting Started"  # 4 questions
  quiz_questions:
    - question: "Given the following data dictionary about school children, create a `pl.DataFrame` and display it. What are the datatypes of each column?"
      answers:
        - text: "(`str`, `str`, `f64`, `cat`)"
          rationale: "Almost! If you want the last column to be a categorical variable, then you'd need to perform some additional type-casting on the column."
          is_correct: false
        - text: "(`str`, `str`, `f64`, `str`)"
          rationale: "Correct! Columns 1, 2, and 4 are strings, but column 3, having at least one value with a decimal point, gets cast as a float."
          is_correct: true
        - text: "(`str`, `str`, `i64`, `cat`)"
          rationale: "Not quite!"
          is_correct: false
        - text: "(`str`, `i64`, `cat`)"
          rationale: "You're missing a column!"
          is_correct: false
    - question: "During the module, we saw that selecting columns from a `LazyFrame` was ~2-3x faster than selecting columns from a `DataFrame`. Now perform the same comparison, but for the `parquet` file. What is the speed increase from selecting on a `DataFrame` to selecting on a `LazyFrame` for the `parquet` file?"
      answers:
        - text: ".5-1x"
          rationale: ""
          is_correct: false
        - text: "1-2x"
          rationale: ""
          is_correct: false
        - text: "3-5x"
          rationale: ""
          is_correct: true
        - text: "5-10x"
          rationale: ""
          is_correct: false
    - question: "Which file type demonstrated a greater speedup from selecting on a `DataFrame` to selecting on a `LazyFrame`: `csv` or `parquet`?"
      answers:
        - text: "`csv`"
          rationale: ""
        - text: "`parquet`"
          rationale: ""
    - question: "Using what you know what you know about `parquet` files, why was selecting on a `LazyFrame` faster than selecting on a `DataFrame` for `parquet` than for `csv`?"
      answers:
        - text: "Because the `parquet` file is smaller than the `csv` file."
          rationale: "Though the `parquet` file is indeed smaller than the `csv` file, this isn't the true reason why it leads to a bigger difference between in-memory selecting vs lazy selecting."
          is_correct: false
        - text: "Because Polars is built on the Apache Arrow memory model, the development team has spent more time developing the functionality associated with parquet, which is also built on the Apache Arrow memory model, thus making its IO operations faster."
          rationale: "While this may be the case, it's not the answer."
          is_correct: false
        - text: "`parquet` files keep data from the same column in the same location in memory, so when the `select` gets pushed down to the read operation of `LazyFrame`, the input engine can skip the unnecessary columns' data faster than it can for `csv`."
          rationale: "Correct! When Polars goes to select only a few columns from a `parquet` file, it only has to read through those few columns' data, while for `csv` it still has to read through every columns' data!"
          is_correct: true
        - text: "Because `parquet` is a newer, more advanced file type."
          rationale: "Though this is indeed true, this isn't the reason why `parquet` has a bigger difference between in-memory selecting vs lazy selecting than `csv`."
          is_correct: false
- module_name: "Data Manipulation I: Basics"  # 10 questions
- module_name: "Data Manipulation II: Advanced Selecting"  # 8 questions
- module_name: "Data Manipulation III: Grouping and Aggregation"  # 10 questions
- module_name: "Data Manipulation IV: Combining Data"  # 5 questions
- module_name: "Data Manipulation V: Data Types"  # 10 questions
- module_name: "Data Manipulation VI: Interoperation"  # 8 questions
- module_name: "Integrating Polars Into the Data Science Workflow"  # 5 questions
- module_name: "Conclusion"
  quiz_questions: []